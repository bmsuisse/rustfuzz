{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a1b2c3d",
   "metadata": {},
   "source": [
    "# Advanced Matching with rustfuzz\n",
    "\n",
    "This notebook covers the full **distance** API, edit operations, alignment objects, and `process.cdist` for pairwise matrices.\n",
    "\n",
    "Topics:\n",
    "1. The `rustfuzz.distance` API — `distance`, `similarity`, `normalized_*`\n",
    "2. Edit-operation objects: `Editops`, `Opcodes`, `MatchingBlock`\n",
    "3. Per-metric deep-dives: Levenshtein, Jaro-Winkler, DamerauLevenshtein, Hamming\n",
    "4. `process.cdist` — pairwise distance matrices\n",
    "5. Real-world deduplication recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2c3d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rustfuzz.distance import (\n",
    "    Levenshtein, Hamming, Indel,\n",
    "    Jaro, JaroWinkler,\n",
    "    LCSseq, OSA, DamerauLevenshtein,\n",
    "    Prefix, Postfix,\n",
    ")\n",
    "from rustfuzz.distance._initialize import Editop, Editops, Opcode, Opcodes, MatchingBlock\n",
    "from rustfuzz import process\n",
    "import rustfuzz.fuzz as fuzz\n",
    "\n",
    "print(\"imports OK ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3d4e5f",
   "metadata": {},
   "source": [
    "## 1. Distance API Overview\n",
    "\n",
    "Every metric module exposes the same interface:\n",
    "\n",
    "| Method | Returns | Meaning |\n",
    "|---|---|---|\n",
    "| `.distance(a, b)` | `int` | Raw edit distance (lower = closer) |\n",
    "| `.similarity(a, b)` | `int` | Matching characters / operations |\n",
    "| `.normalized_distance(a, b)` | `float [0,1]` | 0.0 = identical |\n",
    "| `.normalized_similarity(a, b)` | `float [0,1]` | 1.0 = identical |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4e5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs = [(\"kitten\", \"sitting\"), (\"sunday\", \"saturday\"), (\"rust\", \"trust\")]\n",
    "\n",
    "metrics = [Levenshtein, Hamming, Indel, OSA, DamerauLevenshtein]\n",
    "metric_names = [\"Levenshtein\", \"Hamming\", \"Indel\", \"OSA\", \"DamerauLevenshtein\"]\n",
    "\n",
    "for a, b in word_pairs:\n",
    "    print(f\"\\n── {a!r} vs {b!r} ──\")\n",
    "    for name, M in zip(metric_names, metrics):\n",
    "        try:\n",
    "            d = M.distance(a, b)\n",
    "            nd = M.normalized_distance(a, b)\n",
    "            print(f\"  {name:20}  distance={d:2d}  norm_dist={nd:.3f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {name:20}  N/A ({e})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5f6a7b",
   "metadata": {},
   "source": [
    "## 2. Jaro & Jaro-Winkler\n",
    "\n",
    "Jaro-Winkler is particularly good for **short strings and proper names** — it gives extra weight to a common prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6a7b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_pairs = [\n",
    "    (\"martha\", \"marhta\"),   # transposition\n",
    "    (\"dwayne\", \"duane\"),\n",
    "    (\"john\",   \"jon\"),\n",
    "    (\"smith\",  \"smythe\"),\n",
    "    (\"alice\",  \"bob\"),\n",
    "]\n",
    "\n",
    "print(f\"{'A':10} {'B':10} {'Jaro':>8} {'JaroWinkler':>12}\")\n",
    "print(\"-\" * 45)\n",
    "for a, b in name_pairs:\n",
    "    j  = Jaro.similarity(a, b)\n",
    "    jw = JaroWinkler.similarity(a, b)\n",
    "    print(f\"{a:10} {b:10} {j:8.4f} {jw:12.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7b8c9d",
   "metadata": {},
   "source": [
    "## 3. Edit Operations — `Editops` and `Opcodes`\n",
    "\n",
    "`Levenshtein.editops(a, b)` returns the minimal list of operations (insert, delete, replace) to transform `a` into `b`.\n",
    "\n",
    "`Levenshtein.opcodes(a, b)` returns contiguous blocks in a format compatible with `difflib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c9d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"kitten\"\n",
    "dst = \"sitting\"\n",
    "\n",
    "ops = Levenshtein.editops(src, dst)\n",
    "print(f\"editops({src!r} → {dst!r}):\")\n",
    "for op in ops:\n",
    "    print(f\"  {op}\")\n",
    "\n",
    "print()\n",
    "codes = Levenshtein.opcodes(src, dst)\n",
    "print(f\"opcodes:\")\n",
    "for block in codes:\n",
    "    print(f\"  {block}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9d0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply opcodes to visualise the diff\n",
    "def visualise_diff(src: str, dst: str) -> None:\n",
    "    codes = Levenshtein.opcodes(src, dst)\n",
    "    out = []\n",
    "    for block in codes:\n",
    "        tag = block.tag\n",
    "        s1, s2, d1, d2 = block.src_start, block.src_end, block.dest_start, block.dest_end\n",
    "        if tag == \"equal\":\n",
    "            out.append(src[s1:s2])\n",
    "        elif tag == \"replace\":\n",
    "            out.append(f\"[{src[s1:s2]}→{dst[d1:d2]}]\")\n",
    "        elif tag == \"insert\":\n",
    "            out.append(f\"[+{dst[d1:d2]}]\")\n",
    "        elif tag == \"delete\":\n",
    "            out.append(f\"[-{src[s1:s2]}]\")\n",
    "    print(\"\".join(out))\n",
    "\n",
    "visualise_diff(\"kitten\", \"sitting\")\n",
    "visualise_diff(\"hello world\", \"hello cruel world\")\n",
    "visualise_diff(\"New York City\", \"New Orleans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e1f2a",
   "metadata": {},
   "source": [
    "## 4. Hamming Distance\n",
    "\n",
    "Hamming distance counts **positions where characters differ**. It only works on strings of **equal length**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1f2a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_len_pairs = [\n",
    "    (\"karolin\", \"kathrin\"),\n",
    "    (\"1011101\", \"1001001\"),\n",
    "    (\"GGACTGA\", \"GGCCTGA\"),\n",
    "]\n",
    "\n",
    "for a, b in same_len_pairs:\n",
    "    d  = Hamming.distance(a, b)\n",
    "    ns = Hamming.normalized_similarity(a, b)\n",
    "    print(f\"{a!r} vs {b!r}  → distance={d}  norm_similarity={ns:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a3b4c",
   "metadata": {},
   "source": [
    "## 5. `process.cdist` — Pairwise Distance Matrix\n",
    "\n",
    "Computes a full N×M matrix of similarity scores. Requires `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3b4c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    queries  = [\"New York\", \"Los Angeles\", \"Chicago\"]\n",
    "    choices  = [\"New York City\", \"Los Angeles\", \"Newark\", \"Chicago Heights\", \"New Orleans\"]\n",
    "\n",
    "    matrix = process.cdist(queries, choices, scorer=fuzz.ratio)\n",
    "\n",
    "    df = pd.DataFrame(matrix, index=queries, columns=choices)\n",
    "    print(df.to_string())\n",
    "\n",
    "except ImportError:\n",
    "    print(\"Install numpy + pandas: uv pip install rustfuzz[all] pandas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4c5d6e",
   "metadata": {},
   "source": [
    "## 6. Real-world recipe — Deduplication\n",
    "\n",
    "Group a list of messy city names into deduplicated clusters using `process.extract` and a score threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d6e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rustfuzz.utils as utils\n",
    "\n",
    "messy = [\n",
    "    \"New York\", \"new york\", \"New-York\", \"N.Y.\",\n",
    "    \"Los Angeles\", \"los angeles\", \"L.A.\", \"Los Angles\",\n",
    "    \"Chicago\", \"chicago\", \"Chikago\",\n",
    "    \"Houston\", \"Huston\",\n",
    "]\n",
    "\n",
    "THRESHOLD = 75.0\n",
    "\n",
    "clusters: list[list[str]] = []\n",
    "assigned: set[int] = set()\n",
    "\n",
    "for i, name in enumerate(messy):\n",
    "    if i in assigned:\n",
    "        continue\n",
    "    cluster = [name]\n",
    "    assigned.add(i)\n",
    "    for j, other in enumerate(messy):\n",
    "        if j in assigned:\n",
    "            continue\n",
    "        score = fuzz.token_set_ratio(\n",
    "            utils.default_process(name),\n",
    "            utils.default_process(other),\n",
    "        )\n",
    "        if score >= THRESHOLD:\n",
    "            cluster.append(other)\n",
    "            assigned.add(j)\n",
    "    clusters.append(cluster)\n",
    "\n",
    "for c in clusters:\n",
    "    canonical = c[0]\n",
    "    dupes = c[1:]\n",
    "    print(f\"  {canonical!r:15} ← {dupes}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
