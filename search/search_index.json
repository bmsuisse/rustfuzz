{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p> Blazing-fast fuzzy string matching \u2014 implemented entirely in Rust. Built entirely by AI. Designed to beat RapidFuzz. </p>"},{"location":"#the-story","title":"The Story","text":"<p>rustfuzz started as an experiment: can an AI agent, starting from scratch, build a fuzzy-matching library that outperforms RapidFuzz \u2014 one of the best-optimised C++ string-matching libraries in the Python ecosystem?</p> <p>No human wrote the Rust. No human tuned the algorithm parameters. The AI drove every iteration, read every benchmark result, and decided what to rewrite next.</p> <p>The answer the AI kept coming back to: Rust + PyO3 + tight Python-boundary design.</p>"},{"location":"#the-development-loop","title":"The Development Loop","text":"<p>Every feature and optimisation went through the same cycle:</p> <pre><code>flowchart LR\n    R[\"\ud83d\udd0d Research\\nProfiler output\\n&amp; algorithm gaps\"]\n    B[\"\ud83e\udd80 Build\\nRust core\\nvia PyO3\"]\n    T[\"\u2705 Test\\nAll tests must pass\\nbefore proceeding\"]\n    BM[\"\ud83d\udcca Benchmark\\nvs RapidFuzz\\n&amp; record results\"]\n    RP[\"\ud83d\udd01 Repeat\\nFind the next\\nbottleneck\"]\n\n    R --&gt; B --&gt; T --&gt; BM --&gt; RP --&gt; R\n\n    style R fill:#6366f1,color:#fff,stroke:none\n    style B fill:#a855f7,color:#fff,stroke:none\n    style T fill:#ef4444,color:#fff,stroke:none\n    style BM fill:#22c55e,color:#fff,stroke:none\n    style RP fill:#f59e0b,color:#fff,stroke:none</code></pre> <p>Each iteration asked:</p> <ul> <li>Research \u2014 where is the remaining Python overhead? What does the profiler show?</li> <li>Build \u2014 move that hot path into Rust. Eliminate copies, reduce allocations, avoid iterator protocol overhead.</li> <li>Test \u2014 the full test suite must pass before proceeding. No broken correctness, no skipped edge cases.</li> <li>Benchmark \u2014 run head-to-head comparisons vs RapidFuzz. Numbers don't lie.</li> <li>Repeat \u2014 the next bottleneck is always waiting.</li> </ul>"},{"location":"#why-this-matters","title":"Why This Matters","text":"<p>RapidFuzz is exceptional \u2014 its C++ core, SIMD intrinsics, and decades of optimisation make it a formidable target. The goal of this project was never to dismiss it, but to prove that:</p> <ol> <li>AI can drive non-trivial systems programming \u2014 not just generate boilerplate.</li> <li>Rust + PyO3 can match C++ at the Python boundary \u2014 with the added safety guarantees Rust provides.</li> <li>Iterative AI-driven optimisation works \u2014 each benchmark loop produced measurable gains.</li> </ol>"},{"location":"#features","title":"Features","text":"\u26a1 Blazing Fast Core algorithms in Rust \u2014 no Python overhead, no GIL bottlenecks \ud83e\udde0 Smart Matching ratio, partial_ratio, token sort/set, Levenshtein, Jaro-Winkler, and more \ud83d\udd12 Memory Safe Rust's borrow checker \u2014 no segfaults, no buffer overflows \ud83d\udc0d Pythonic API Typed Python interface \u2014 <code>import rustfuzz.fuzz as fuzz</code> and go \ud83d\udce6 No Build Step Pre-compiled wheels for Python 3.10\u20133.13 on Linux, macOS, and Windows"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install rustfuzz\n# or with uv:\nuv pip install rustfuzz\n</code></pre>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import rustfuzz.fuzz as fuzz\nfrom rustfuzz.distance import Levenshtein, JaroWinkler\nfrom rustfuzz import process\n\n# Similarity ratios\nfuzz.ratio(\"hello world\", \"hello wrold\")            # ~96.0\nfuzz.partial_ratio(\"hello\", \"say hello world\")      # 100.0\nfuzz.token_sort_ratio(\"fuzzy wuzzy\", \"wuzzy fuzzy\") # 100.0\n\n# Edit distance\nLevenshtein.distance(\"kitten\", \"sitting\")           # 3\nJaroWinkler.similarity(\"martha\", \"marhta\")          # ~0.96\n\n# Batch matching\nprocess.extractOne(\"new york\", [\"New York\", \"Newark\", \"Los Angeles\"])\n# ('New York', 100.0, 0)\n</code></pre>"},{"location":"#cookbook-recipes","title":"Cookbook Recipes \ud83e\uddd1\u200d\ud83c\udf73","text":"Recipe Description Introduction Get started \u2014 basic matching and terminology Advanced Matching Partial ratios, token sorts, score cutoffs Benchmarks Head-to-head speed comparisons vs RapidFuzz <p>Start exploring from the navigation menu on the left!</p>"},{"location":"cookbook/01_introduction/","title":"Introduction to rustfuzz","text":"In\u00a0[\u00a0]: Copied! <pre>import rustfuzz.fuzz as fuzz\nimport rustfuzz.utils as utils\nfrom rustfuzz import process\n\nprint(\"rustfuzz ready \u2705\")\n</pre> import rustfuzz.fuzz as fuzz import rustfuzz.utils as utils from rustfuzz import process  print(\"rustfuzz ready \u2705\") In\u00a0[\u00a0]: Copied! <pre>pairs = [\n    (\"hello world\", \"hello world\"),   # identical\n    (\"hello world\", \"hello wrold\"),   # one transposition\n    (\"hello world\", \"hello\"),         # truncated\n    (\"New York\",    \"New York City\"), # prefix\n    (\"kitten\",      \"sitting\"),       # classic Levenshtein example\n    (\"apple\",       \"mango\"),         # unrelated\n]\n\nfor a, b in pairs:\n    print(f\"{a!r:25} vs {b!r:25}  \u2192 ratio = {fuzz.ratio(a, b):.1f}\")\n</pre> pairs = [     (\"hello world\", \"hello world\"),   # identical     (\"hello world\", \"hello wrold\"),   # one transposition     (\"hello world\", \"hello\"),         # truncated     (\"New York\",    \"New York City\"), # prefix     (\"kitten\",      \"sitting\"),       # classic Levenshtein example     (\"apple\",       \"mango\"),         # unrelated ]  for a, b in pairs:     print(f\"{a!r:25} vs {b!r:25}  \u2192 ratio = {fuzz.ratio(a, b):.1f}\") In\u00a0[\u00a0]: Copied! <pre>needle = \"New York\"\nhaystacks = [\n    \"I live in New York City\",\n    \"New York is great\",\n    \"nyc\",\n    \"Los Angeles\",\n]\n\nfor h in haystacks:\n    r  = fuzz.ratio(needle, h)\n    pr = fuzz.partial_ratio(needle, h)\n    print(f\"{h!r:30}  ratio={r:5.1f}  partial_ratio={pr:5.1f}\")\n</pre> needle = \"New York\" haystacks = [     \"I live in New York City\",     \"New York is great\",     \"nyc\",     \"Los Angeles\", ]  for h in haystacks:     r  = fuzz.ratio(needle, h)     pr = fuzz.partial_ratio(needle, h)     print(f\"{h!r:30}  ratio={r:5.1f}  partial_ratio={pr:5.1f}\") In\u00a0[\u00a0]: Copied! <pre>a = \"fuzzy wuzzy was a bear\"\nb = \"wuzzy fuzzy was a bear\"\n\nprint(f\"ratio              = {fuzz.ratio(a, b):.1f}\")\nprint(f\"token_sort_ratio   = {fuzz.token_sort_ratio(a, b):.1f}\")\nprint(f\"token_set_ratio    = {fuzz.token_set_ratio(a, b):.1f}\")\nprint(f\"token_ratio        = {fuzz.token_ratio(a, b):.1f}\")\n\nprint()\n\n# Subset: token_set_ratio handles extra tokens gracefully\nc = \"fuzzy fuzzy was a bear\"\nprint(f\"token_set_ratio (with duplicate token): {fuzz.token_set_ratio(a, c):.1f}\")\n</pre> a = \"fuzzy wuzzy was a bear\" b = \"wuzzy fuzzy was a bear\"  print(f\"ratio              = {fuzz.ratio(a, b):.1f}\") print(f\"token_sort_ratio   = {fuzz.token_sort_ratio(a, b):.1f}\") print(f\"token_set_ratio    = {fuzz.token_set_ratio(a, b):.1f}\") print(f\"token_ratio        = {fuzz.token_ratio(a, b):.1f}\")  print()  # Subset: token_set_ratio handles extra tokens gracefully c = \"fuzzy fuzzy was a bear\" print(f\"token_set_ratio (with duplicate token): {fuzz.token_set_ratio(a, c):.1f}\") In\u00a0[\u00a0]: Copied! <pre>raw_strings = [\n    \"  Hello, World!  \",\n    \"RustFuzz \u2014 BLAZING FAST!\",\n    \"New York, NY 10001\",\n    None,\n]\n\nfor s in raw_strings:\n    print(f\"{str(s)!r:35} \u2192 {utils.default_process(s)!r}\")\n\nprint()\n# Using processor in ratio call\nscore_raw = fuzz.ratio(\"New York, NY\", \"new york ny\")\nscore_proc = fuzz.ratio(\n    utils.default_process(\"New York, NY\"),\n    utils.default_process(\"new york ny\")\n)\nprint(f\"Without processing: {score_raw:.1f}\")\nprint(f\"With processing:    {score_proc:.1f}\")\n</pre> raw_strings = [     \"  Hello, World!  \",     \"RustFuzz \u2014 BLAZING FAST!\",     \"New York, NY 10001\",     None, ]  for s in raw_strings:     print(f\"{str(s)!r:35} \u2192 {utils.default_process(s)!r}\")  print() # Using processor in ratio call score_raw = fuzz.ratio(\"New York, NY\", \"new york ny\") score_proc = fuzz.ratio(     utils.default_process(\"New York, NY\"),     utils.default_process(\"new york ny\") ) print(f\"Without processing: {score_raw:.1f}\") print(f\"With processing:    {score_proc:.1f}\") In\u00a0[\u00a0]: Copied! <pre>cities = [\n    \"New York\", \"New Orleans\", \"Newark\",\n    \"Los Angeles\", \"San Francisco\", \"Nashville\",\n    \"Boston\", \"Denver\", \"Miami\",\n]\n\nquery = \"new york\"\n\nprint(\"Top 3 matches:\")\nfor choice, score, idx in process.extract(query, cities, limit=3):\n    print(f\"  {choice:20} score={score:5.1f}  (index {idx})\")\n\nprint()\nbest = process.extractOne(query, cities)\nprint(f\"Best match: {best}\")\n</pre> cities = [     \"New York\", \"New Orleans\", \"Newark\",     \"Los Angeles\", \"San Francisco\", \"Nashville\",     \"Boston\", \"Denver\", \"Miami\", ]  query = \"new york\"  print(\"Top 3 matches:\") for choice, score, idx in process.extract(query, cities, limit=3):     print(f\"  {choice:20} score={score:5.1f}  (index {idx})\")  print() best = process.extractOne(query, cities) print(f\"Best match: {best}\") In\u00a0[\u00a0]: Copied! <pre># Only keep matches with score &gt;= 80\nresults = process.extract(\"berlin\", cities, score_cutoff=80.0)\nprint(f\"Matches &gt;= 80 for 'berlin': {results}\")\n\n# Cutoff in raw scorer\ns = fuzz.ratio(\"hello\", \"world\", score_cutoff=90.0)\nprint(f\"ratio('hello','world', cutoff=90) = {s}  (below cutoff \u2192 0.0)\")\n</pre> # Only keep matches with score &gt;= 80 results = process.extract(\"berlin\", cities, score_cutoff=80.0) print(f\"Matches &gt;= 80 for 'berlin': {results}\")  # Cutoff in raw scorer s = fuzz.ratio(\"hello\", \"world\", score_cutoff=90.0) print(f\"ratio('hello','world', cutoff=90) = {s}  (below cutoff \u2192 0.0)\")"},{"location":"cookbook/01_introduction/#introduction-to-rustfuzz","title":"Introduction to rustfuzz\u00b6","text":"<p><code>rustfuzz</code> is a blazing-fast fuzzy string matching library for Python \u2014 implemented entirely in Rust via PyO3.</p> <p>This notebook covers the core building blocks:</p> <ul> <li><code>fuzz.ratio</code> \u2014 character-level similarity</li> <li><code>fuzz.partial_ratio</code> \u2014 substring matching</li> <li><code>fuzz.token_*</code> \u2014 word-order insensitive matching</li> <li><code>utils.default_process</code> \u2014 string normalisation</li> <li><code>process.extract</code> / <code>process.extractOne</code> \u2014 batch matching</li> </ul>"},{"location":"cookbook/01_introduction/#1-fuzzratio-character-level-similarity","title":"1. <code>fuzz.ratio</code> \u2014 Character-level similarity\u00b6","text":"<p>Returns a score from <code>0.0</code> to <code>100.0</code> based on the Indel (insert/delete) distance between two strings. Identical strings \u2192 100.0. Completely different \u2192 0.0.</p>"},{"location":"cookbook/01_introduction/#2-fuzzpartial_ratio-substring-matching","title":"2. <code>fuzz.partial_ratio</code> \u2014 Substring matching\u00b6","text":"<p>Finds the best matching window of the shorter string inside the longer one. Ideal when the needle is fully contained in the haystack.</p>"},{"location":"cookbook/01_introduction/#3-token-ratios-word-order-insensitive-matching","title":"3. Token ratios \u2014 Word-order insensitive matching\u00b6","text":"Function What it does <code>token_sort_ratio</code> Sorts tokens alphabetically, then computes <code>ratio</code> <code>token_set_ratio</code> Compares the intersection and remainder sets of tokens <code>token_ratio</code> <code>max(token_sort_ratio, token_set_ratio)</code> <p>Use these when word order shouldn't matter (e.g. address matching, name deduplication).</p>"},{"location":"cookbook/01_introduction/#4-utilsdefault_process-normalisation","title":"4. <code>utils.default_process</code> \u2014 Normalisation\u00b6","text":"<p>Lowercases the string and replaces non-alphanumeric characters with spaces. Pass it as the <code>processor</code> argument to any scorer for more robust matching.</p>"},{"location":"cookbook/01_introduction/#5-processextract-processextractone-batch-matching","title":"5. <code>process.extract</code> / <code>process.extractOne</code> \u2014 Batch matching\u00b6","text":"<p>Match a query against a list of choices and get the top results. Each result is a <code>(choice, score, index)</code> tuple.</p>"},{"location":"cookbook/01_introduction/#6-score-cutoffs","title":"6. Score cutoffs\u00b6","text":"<p>All scorers accept a <code>score_cutoff</code> parameter. Results below the threshold are returned as <code>0.0</code> (or excluded from <code>process.extract</code>).</p>"},{"location":"cookbook/02_advanced_matching/","title":"Advanced Matching with rustfuzz","text":"In\u00a0[\u00a0]: Copied! <pre>from rustfuzz.distance import (\n    Levenshtein, Hamming, Indel,\n    Jaro, JaroWinkler,\n    LCSseq, OSA, DamerauLevenshtein,\n    Prefix, Postfix,\n)\nfrom rustfuzz.distance._initialize import Editop, Editops, Opcode, Opcodes, MatchingBlock\nfrom rustfuzz import process\nimport rustfuzz.fuzz as fuzz\n\nprint(\"imports OK \u2705\")\n</pre> from rustfuzz.distance import (     Levenshtein, Hamming, Indel,     Jaro, JaroWinkler,     LCSseq, OSA, DamerauLevenshtein,     Prefix, Postfix, ) from rustfuzz.distance._initialize import Editop, Editops, Opcode, Opcodes, MatchingBlock from rustfuzz import process import rustfuzz.fuzz as fuzz  print(\"imports OK \u2705\") In\u00a0[\u00a0]: Copied! <pre>word_pairs = [(\"kitten\", \"sitting\"), (\"sunday\", \"saturday\"), (\"rust\", \"trust\")]\n\nmetrics = [Levenshtein, Hamming, Indel, OSA, DamerauLevenshtein]\nmetric_names = [\"Levenshtein\", \"Hamming\", \"Indel\", \"OSA\", \"DamerauLevenshtein\"]\n\nfor a, b in word_pairs:\n    print(f\"\\n\u2500\u2500 {a!r} vs {b!r} \u2500\u2500\")\n    for name, M in zip(metric_names, metrics):\n        try:\n            d = M.distance(a, b)\n            nd = M.normalized_distance(a, b)\n            print(f\"  {name:20}  distance={d:2d}  norm_dist={nd:.3f}\")\n        except Exception as e:\n            print(f\"  {name:20}  N/A ({e})\")\n</pre> word_pairs = [(\"kitten\", \"sitting\"), (\"sunday\", \"saturday\"), (\"rust\", \"trust\")]  metrics = [Levenshtein, Hamming, Indel, OSA, DamerauLevenshtein] metric_names = [\"Levenshtein\", \"Hamming\", \"Indel\", \"OSA\", \"DamerauLevenshtein\"]  for a, b in word_pairs:     print(f\"\\n\u2500\u2500 {a!r} vs {b!r} \u2500\u2500\")     for name, M in zip(metric_names, metrics):         try:             d = M.distance(a, b)             nd = M.normalized_distance(a, b)             print(f\"  {name:20}  distance={d:2d}  norm_dist={nd:.3f}\")         except Exception as e:             print(f\"  {name:20}  N/A ({e})\") In\u00a0[\u00a0]: Copied! <pre>name_pairs = [\n    (\"martha\", \"marhta\"),   # transposition\n    (\"dwayne\", \"duane\"),\n    (\"john\",   \"jon\"),\n    (\"smith\",  \"smythe\"),\n    (\"alice\",  \"bob\"),\n]\n\nprint(f\"{'A':10} {'B':10} {'Jaro':&gt;8} {'JaroWinkler':&gt;12}\")\nprint(\"-\" * 45)\nfor a, b in name_pairs:\n    j  = Jaro.similarity(a, b)\n    jw = JaroWinkler.similarity(a, b)\n    print(f\"{a:10} {b:10} {j:8.4f} {jw:12.4f}\")\n</pre> name_pairs = [     (\"martha\", \"marhta\"),   # transposition     (\"dwayne\", \"duane\"),     (\"john\",   \"jon\"),     (\"smith\",  \"smythe\"),     (\"alice\",  \"bob\"), ]  print(f\"{'A':10} {'B':10} {'Jaro':&gt;8} {'JaroWinkler':&gt;12}\") print(\"-\" * 45) for a, b in name_pairs:     j  = Jaro.similarity(a, b)     jw = JaroWinkler.similarity(a, b)     print(f\"{a:10} {b:10} {j:8.4f} {jw:12.4f}\") In\u00a0[\u00a0]: Copied! <pre>src = \"kitten\"\ndst = \"sitting\"\n\nops = Levenshtein.editops(src, dst)\nprint(f\"editops({src!r} \u2192 {dst!r}):\")\nfor op in ops:\n    print(f\"  {op}\")\n\nprint()\ncodes = Levenshtein.opcodes(src, dst)\nprint(f\"opcodes:\")\nfor block in codes:\n    print(f\"  {block}\")\n</pre> src = \"kitten\" dst = \"sitting\"  ops = Levenshtein.editops(src, dst) print(f\"editops({src!r} \u2192 {dst!r}):\") for op in ops:     print(f\"  {op}\")  print() codes = Levenshtein.opcodes(src, dst) print(f\"opcodes:\") for block in codes:     print(f\"  {block}\") In\u00a0[\u00a0]: Copied! <pre># Apply opcodes to visualise the diff\ndef visualise_diff(src: str, dst: str) -&gt; None:\n    codes = Levenshtein.opcodes(src, dst)\n    out = []\n    for block in codes:\n        tag = block.tag\n        s1, s2, d1, d2 = block.src_start, block.src_end, block.dest_start, block.dest_end\n        if tag == \"equal\":\n            out.append(src[s1:s2])\n        elif tag == \"replace\":\n            out.append(f\"[{src[s1:s2]}\u2192{dst[d1:d2]}]\")\n        elif tag == \"insert\":\n            out.append(f\"[+{dst[d1:d2]}]\")\n        elif tag == \"delete\":\n            out.append(f\"[-{src[s1:s2]}]\")\n    print(\"\".join(out))\n\nvisualise_diff(\"kitten\", \"sitting\")\nvisualise_diff(\"hello world\", \"hello cruel world\")\nvisualise_diff(\"New York City\", \"New Orleans\")\n</pre> # Apply opcodes to visualise the diff def visualise_diff(src: str, dst: str) -&gt; None:     codes = Levenshtein.opcodes(src, dst)     out = []     for block in codes:         tag = block.tag         s1, s2, d1, d2 = block.src_start, block.src_end, block.dest_start, block.dest_end         if tag == \"equal\":             out.append(src[s1:s2])         elif tag == \"replace\":             out.append(f\"[{src[s1:s2]}\u2192{dst[d1:d2]}]\")         elif tag == \"insert\":             out.append(f\"[+{dst[d1:d2]}]\")         elif tag == \"delete\":             out.append(f\"[-{src[s1:s2]}]\")     print(\"\".join(out))  visualise_diff(\"kitten\", \"sitting\") visualise_diff(\"hello world\", \"hello cruel world\") visualise_diff(\"New York City\", \"New Orleans\") In\u00a0[\u00a0]: Copied! <pre>same_len_pairs = [\n    (\"karolin\", \"kathrin\"),\n    (\"1011101\", \"1001001\"),\n    (\"GGACTGA\", \"GGCCTGA\"),\n]\n\nfor a, b in same_len_pairs:\n    d  = Hamming.distance(a, b)\n    ns = Hamming.normalized_similarity(a, b)\n    print(f\"{a!r} vs {b!r}  \u2192 distance={d}  norm_similarity={ns:.3f}\")\n</pre> same_len_pairs = [     (\"karolin\", \"kathrin\"),     (\"1011101\", \"1001001\"),     (\"GGACTGA\", \"GGCCTGA\"), ]  for a, b in same_len_pairs:     d  = Hamming.distance(a, b)     ns = Hamming.normalized_similarity(a, b)     print(f\"{a!r} vs {b!r}  \u2192 distance={d}  norm_similarity={ns:.3f}\") In\u00a0[\u00a0]: Copied! <pre>try:\n    import numpy as np\n    import pandas as pd\n\n    queries  = [\"New York\", \"Los Angeles\", \"Chicago\"]\n    choices  = [\"New York City\", \"Los Angeles\", \"Newark\", \"Chicago Heights\", \"New Orleans\"]\n\n    matrix = process.cdist(queries, choices, scorer=fuzz.ratio)\n\n    df = pd.DataFrame(matrix, index=queries, columns=choices)\n    print(df.to_string())\n\nexcept ImportError:\n    print(\"Install numpy + pandas: uv pip install rustfuzz[all] pandas\")\n</pre> try:     import numpy as np     import pandas as pd      queries  = [\"New York\", \"Los Angeles\", \"Chicago\"]     choices  = [\"New York City\", \"Los Angeles\", \"Newark\", \"Chicago Heights\", \"New Orleans\"]      matrix = process.cdist(queries, choices, scorer=fuzz.ratio)      df = pd.DataFrame(matrix, index=queries, columns=choices)     print(df.to_string())  except ImportError:     print(\"Install numpy + pandas: uv pip install rustfuzz[all] pandas\") In\u00a0[\u00a0]: Copied! <pre>import rustfuzz.utils as utils\n\nmessy = [\n    \"New York\", \"new york\", \"New-York\", \"N.Y.\",\n    \"Los Angeles\", \"los angeles\", \"L.A.\", \"Los Angles\",\n    \"Chicago\", \"chicago\", \"Chikago\",\n    \"Houston\", \"Huston\",\n]\n\nTHRESHOLD = 75.0\n\nclusters: list[list[str]] = []\nassigned: set[int] = set()\n\nfor i, name in enumerate(messy):\n    if i in assigned:\n        continue\n    cluster = [name]\n    assigned.add(i)\n    for j, other in enumerate(messy):\n        if j in assigned:\n            continue\n        score = fuzz.token_set_ratio(\n            utils.default_process(name),\n            utils.default_process(other),\n        )\n        if score &gt;= THRESHOLD:\n            cluster.append(other)\n            assigned.add(j)\n    clusters.append(cluster)\n\nfor c in clusters:\n    canonical = c[0]\n    dupes = c[1:]\n    print(f\"  {canonical!r:15} \u2190 {dupes}\")\n</pre> import rustfuzz.utils as utils  messy = [     \"New York\", \"new york\", \"New-York\", \"N.Y.\",     \"Los Angeles\", \"los angeles\", \"L.A.\", \"Los Angles\",     \"Chicago\", \"chicago\", \"Chikago\",     \"Houston\", \"Huston\", ]  THRESHOLD = 75.0  clusters: list[list[str]] = [] assigned: set[int] = set()  for i, name in enumerate(messy):     if i in assigned:         continue     cluster = [name]     assigned.add(i)     for j, other in enumerate(messy):         if j in assigned:             continue         score = fuzz.token_set_ratio(             utils.default_process(name),             utils.default_process(other),         )         if score &gt;= THRESHOLD:             cluster.append(other)             assigned.add(j)     clusters.append(cluster)  for c in clusters:     canonical = c[0]     dupes = c[1:]     print(f\"  {canonical!r:15} \u2190 {dupes}\")"},{"location":"cookbook/02_advanced_matching/#advanced-matching-with-rustfuzz","title":"Advanced Matching with rustfuzz\u00b6","text":"<p>This notebook covers the full distance API, edit operations, alignment objects, and <code>process.cdist</code> for pairwise matrices.</p> <p>Topics:</p> <ol> <li>The <code>rustfuzz.distance</code> API \u2014 <code>distance</code>, <code>similarity</code>, <code>normalized_*</code></li> <li>Edit-operation objects: <code>Editops</code>, <code>Opcodes</code>, <code>MatchingBlock</code></li> <li>Per-metric deep-dives: Levenshtein, Jaro-Winkler, DamerauLevenshtein, Hamming</li> <li><code>process.cdist</code> \u2014 pairwise distance matrices</li> <li>Real-world deduplication recipe</li> </ol>"},{"location":"cookbook/02_advanced_matching/#1-distance-api-overview","title":"1. Distance API Overview\u00b6","text":"<p>Every metric module exposes the same interface:</p> Method Returns Meaning <code>.distance(a, b)</code> <code>int</code> Raw edit distance (lower = closer) <code>.similarity(a, b)</code> <code>int</code> Matching characters / operations <code>.normalized_distance(a, b)</code> <code>float [0,1]</code> 0.0 = identical <code>.normalized_similarity(a, b)</code> <code>float [0,1]</code> 1.0 = identical"},{"location":"cookbook/02_advanced_matching/#2-jaro-jaro-winkler","title":"2. Jaro &amp; Jaro-Winkler\u00b6","text":"<p>Jaro-Winkler is particularly good for short strings and proper names \u2014 it gives extra weight to a common prefix.</p>"},{"location":"cookbook/02_advanced_matching/#3-edit-operations-editops-and-opcodes","title":"3. Edit Operations \u2014 <code>Editops</code> and <code>Opcodes</code>\u00b6","text":"<p><code>Levenshtein.editops(a, b)</code> returns the minimal list of operations (insert, delete, replace) to transform <code>a</code> into <code>b</code>.</p> <p><code>Levenshtein.opcodes(a, b)</code> returns contiguous blocks in a format compatible with <code>difflib</code>.</p>"},{"location":"cookbook/02_advanced_matching/#4-hamming-distance","title":"4. Hamming Distance\u00b6","text":"<p>Hamming distance counts positions where characters differ. It only works on strings of equal length.</p>"},{"location":"cookbook/02_advanced_matching/#5-processcdist-pairwise-distance-matrix","title":"5. <code>process.cdist</code> \u2014 Pairwise Distance Matrix\u00b6","text":"<p>Computes a full N\u00d7M matrix of similarity scores. Requires <code>numpy</code>.</p>"},{"location":"cookbook/02_advanced_matching/#6-real-world-recipe-deduplication","title":"6. Real-world recipe \u2014 Deduplication\u00b6","text":"<p>Group a list of messy city names into deduplicated clusters using <code>process.extract</code> and a score threshold.</p>"},{"location":"cookbook/03_benchmarks/","title":"Performance Benchmarks","text":"In\u00a0[\u00a0]: Copied! <pre>import timeit\nimport rustfuzz.fuzz as fuzz\nfrom rustfuzz.distance import Levenshtein, JaroWinkler, Hamming, DamerauLevenshtein\n\nN = 10_000\nS1, S2 = \"the quick brown fox jumps over the lazy dog\", \"the quick brown fox jumped over a lazy dog\"\n\nprint(f\"Strings:\\n  s1 = {S1!r}\\n  s2 = {S2!r}\\n\")\nprint(f\"Iterations: {N:,}\")\n</pre> import timeit import rustfuzz.fuzz as fuzz from rustfuzz.distance import Levenshtein, JaroWinkler, Hamming, DamerauLevenshtein  N = 10_000 S1, S2 = \"the quick brown fox jumps over the lazy dog\", \"the quick brown fox jumped over a lazy dog\"  print(f\"Strings:\\n  s1 = {S1!r}\\n  s2 = {S2!r}\\n\") print(f\"Iterations: {N:,}\") In\u00a0[\u00a0]: Copied! <pre>def bench(fn, *args, n=N) -&gt; float:\n    \"\"\"Return milliseconds per call (median of 5 runs).\"\"\"\n    times = timeit.repeat(lambda: fn(*args), number=n, repeat=5)\n    return min(times) / n * 1000  # ms per call\n\n\nbenchmarks = {\n    \"fuzz.ratio\":                lambda: fuzz.ratio(S1, S2),\n    \"fuzz.partial_ratio\":        lambda: fuzz.partial_ratio(S1, S2),\n    \"fuzz.token_sort_ratio\":     lambda: fuzz.token_sort_ratio(S1, S2),\n    \"fuzz.token_set_ratio\":      lambda: fuzz.token_set_ratio(S1, S2),\n    \"fuzz.WRatio\":               lambda: fuzz.WRatio(S1, S2),\n    \"Levenshtein.distance\":      lambda: Levenshtein.distance(S1, S2),\n    \"Levenshtein.normalized\":    lambda: Levenshtein.normalized_similarity(S1, S2),\n    \"JaroWinkler.similarity\":    lambda: JaroWinkler.similarity(S1, S2),\n    \"DamerauLevenshtein.dist\":   lambda: DamerauLevenshtein.distance(S1, S2),\n}\n\nresults: dict[str, float] = {}\n\nfor name, fn in benchmarks.items():\n    ms = bench(fn)\n    results[name] = ms\n    print(f\"  {name:35}  {ms*1000:.3f} \u03bcs/call\")\n\nprint(\"\\n\u2705 All benchmarks complete\")\n</pre> def bench(fn, *args, n=N) -&gt; float:     \"\"\"Return milliseconds per call (median of 5 runs).\"\"\"     times = timeit.repeat(lambda: fn(*args), number=n, repeat=5)     return min(times) / n * 1000  # ms per call   benchmarks = {     \"fuzz.ratio\":                lambda: fuzz.ratio(S1, S2),     \"fuzz.partial_ratio\":        lambda: fuzz.partial_ratio(S1, S2),     \"fuzz.token_sort_ratio\":     lambda: fuzz.token_sort_ratio(S1, S2),     \"fuzz.token_set_ratio\":      lambda: fuzz.token_set_ratio(S1, S2),     \"fuzz.WRatio\":               lambda: fuzz.WRatio(S1, S2),     \"Levenshtein.distance\":      lambda: Levenshtein.distance(S1, S2),     \"Levenshtein.normalized\":    lambda: Levenshtein.normalized_similarity(S1, S2),     \"JaroWinkler.similarity\":    lambda: JaroWinkler.similarity(S1, S2),     \"DamerauLevenshtein.dist\":   lambda: DamerauLevenshtein.distance(S1, S2), }  results: dict[str, float] = {}  for name, fn in benchmarks.items():     ms = bench(fn)     results[name] = ms     print(f\"  {name:35}  {ms*1000:.3f} \u03bcs/call\")  print(\"\\n\u2705 All benchmarks complete\") In\u00a0[\u00a0]: Copied! <pre>try:\n    import plotly.graph_objects as go\n\n    ops   = list(results.keys())\n    times = [v * 1000 for v in results.values()]  # \u03bcs\n\n    colors = [\n        f\"rgba({int(168 + i*4)},{int(85 - i*2)},{int(247 - i*10)},0.85)\"\n        for i in range(len(ops))\n    ]\n\n    fig = go.Figure(go.Bar(\n        x=ops,\n        y=times,\n        marker_color=colors,\n        text=[f\"{t:.2f} \u03bcs\" for t in times],\n        textposition=\"outside\",\n    ))\n    fig.update_layout(\n        title=\"rustfuzz \u2014 microseconds per call (lower is better)\",\n        xaxis_title=\"Operation\",\n        yaxis_title=\"\u03bcs / call\",\n        paper_bgcolor=\"#0f0319\",\n        plot_bgcolor=\"#1a0533\",\n        font=dict(color=\"#d8b4fe\"),\n        xaxis=dict(tickangle=-30),\n    )\n    fig.show()\n\nexcept ImportError:\n    print(\"Install plotly: uv pip install plotly\")\n    for name, ms in results.items():\n        bar = \"\u2588\" * int(ms * 1000 / max(results.values()) * 40)\n        print(f\"  {name:35} {bar} {ms*1000:.2f} \u03bcs\")\n</pre> try:     import plotly.graph_objects as go      ops   = list(results.keys())     times = [v * 1000 for v in results.values()]  # \u03bcs      colors = [         f\"rgba({int(168 + i*4)},{int(85 - i*2)},{int(247 - i*10)},0.85)\"         for i in range(len(ops))     ]      fig = go.Figure(go.Bar(         x=ops,         y=times,         marker_color=colors,         text=[f\"{t:.2f} \u03bcs\" for t in times],         textposition=\"outside\",     ))     fig.update_layout(         title=\"rustfuzz \u2014 microseconds per call (lower is better)\",         xaxis_title=\"Operation\",         yaxis_title=\"\u03bcs / call\",         paper_bgcolor=\"#0f0319\",         plot_bgcolor=\"#1a0533\",         font=dict(color=\"#d8b4fe\"),         xaxis=dict(tickangle=-30),     )     fig.show()  except ImportError:     print(\"Install plotly: uv pip install plotly\")     for name, ms in results.items():         bar = \"\u2588\" * int(ms * 1000 / max(results.values()) * 40)         print(f\"  {name:35} {bar} {ms*1000:.2f} \u03bcs\") In\u00a0[\u00a0]: Copied! <pre>import string, random\nrandom.seed(42)\n\ndef rand_str(n: int) -&gt; str:\n    return \"\".join(random.choices(string.ascii_lowercase, k=n))\n\nlengths = [10, 50, 100, 250, 500, 1000]\nscale_results: dict[int, float] = {}\n\nfor length in lengths:\n    a, b = rand_str(length), rand_str(length)\n    ms = bench(Levenshtein.distance, a, b, n=1000)\n    scale_results[length] = ms * 1000  # \u03bcs\n    print(f\"  len={length:5d}  {ms*1000:.3f} \u03bcs/call\")\n</pre> import string, random random.seed(42)  def rand_str(n: int) -&gt; str:     return \"\".join(random.choices(string.ascii_lowercase, k=n))  lengths = [10, 50, 100, 250, 500, 1000] scale_results: dict[int, float] = {}  for length in lengths:     a, b = rand_str(length), rand_str(length)     ms = bench(Levenshtein.distance, a, b, n=1000)     scale_results[length] = ms * 1000  # \u03bcs     print(f\"  len={length:5d}  {ms*1000:.3f} \u03bcs/call\") In\u00a0[\u00a0]: Copied! <pre>try:\n    import plotly.graph_objects as go\n\n    fig = go.Figure(go.Scatter(\n        x=list(scale_results.keys()),\n        y=list(scale_results.values()),\n        mode=\"lines+markers\",\n        line=dict(color=\"#a855f7\", width=3),\n        marker=dict(color=\"#22c55e\", size=10),\n    ))\n    fig.update_layout(\n        title=\"Levenshtein.distance \u2014 scaling by string length\",\n        xaxis_title=\"String length (chars)\",\n        yaxis_title=\"\u03bcs / call\",\n        paper_bgcolor=\"#0f0319\",\n        plot_bgcolor=\"#1a0533\",\n        font=dict(color=\"#d8b4fe\"),\n    )\n    fig.show()\n\nexcept ImportError:\n    for length, us in scale_results.items():\n        print(f\"  len={length:4d}  {us:.3f} \u03bcs\")\n</pre> try:     import plotly.graph_objects as go      fig = go.Figure(go.Scatter(         x=list(scale_results.keys()),         y=list(scale_results.values()),         mode=\"lines+markers\",         line=dict(color=\"#a855f7\", width=3),         marker=dict(color=\"#22c55e\", size=10),     ))     fig.update_layout(         title=\"Levenshtein.distance \u2014 scaling by string length\",         xaxis_title=\"String length (chars)\",         yaxis_title=\"\u03bcs / call\",         paper_bgcolor=\"#0f0319\",         plot_bgcolor=\"#1a0533\",         font=dict(color=\"#d8b4fe\"),     )     fig.show()  except ImportError:     for length, us in scale_results.items():         print(f\"  len={length:4d}  {us:.3f} \u03bcs\")"},{"location":"cookbook/03_benchmarks/#performance-benchmarks","title":"Performance Benchmarks\u00b6","text":"<p>This notebook measures <code>rustfuzz</code> performance using Python's <code>timeit</code> and visualises results with <code>plotly</code>.</p> <p>All benchmarks run N = 10,000 iterations on a fixed string pair to produce stable measurements.</p>"},{"location":"cookbook/03_benchmarks/#results-bar-chart","title":"Results \u2014 Bar Chart\u00b6","text":""},{"location":"cookbook/03_benchmarks/#scaling-benchmark-string-length","title":"Scaling benchmark \u2014 string length\u00b6","text":"<p>How does <code>Levenshtein.distance</code> scale with string length?</p>"}]}